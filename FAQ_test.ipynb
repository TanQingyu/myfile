{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da3034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volumes',\n",
       " '.ipynb_checkpoints',\n",
       " 'README.md',\n",
       " 'FAQ_embeddings_20230906.npy',\n",
       " 'FAQ_embeddings.npy',\n",
       " '.git',\n",
       " 'docker-compose.yml']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0908 01:52:09.078355758    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.listdir(\"../../myfile/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d5ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    connections,\n",
    "    utility,\n",
    ")\n",
    "\n",
    "# from config import CONFIG\n",
    "\n",
    "# from data_file_path import VECTOR_DATA, \n",
    "#FAQ_ALL_DATA = \"../../myfile/FAQ_embeddings.npy\"\n",
    "FAQ_ALL_DATA = \"../../myfile/FAQ_embeddings_20230906.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12862c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# MILVUS_CONFIG = CONFIG[\"Milvus\"]\n",
    "MILVUS_HOST = \"3.68.74.215\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "COLLECTION_NAME = \"MA_FAQ_CACHE\"\n",
    "# COLLECTION_NAME = \"FAQ_feat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1eda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70345040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(string: str) -> int:\n",
    "    hashed_string = hashlib.sha256(string.encode()).hexdigest()\n",
    "    int_id = int(hashed_string, 16) % (2**63 - 1)\n",
    "    return int_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a358d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema():\n",
    "    \"\"\"TODO: create schema for milvus, the filed is defined\n",
    "    Returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # PK\n",
    "    ids = FieldSchema(\n",
    "        name=\"id\",\n",
    "        dtype=DataType.INT64,\n",
    "        is_primary=True,\n",
    "        # auto_id = True\n",
    "    )\n",
    "    # question\n",
    "    question = FieldSchema(name=\"question\", dtype=DataType.VARCHAR, max_length=200)\n",
    "    # vector\n",
    "    features = FieldSchema(name=\"features\", dtype=DataType.FLOAT_VECTOR, dim=1536)\n",
    "    meta = FieldSchema(name=\"meta\", dtype=DataType.VARCHAR, max_length=2000)\n",
    "    schema = CollectionSchema(\n",
    "        fields=[\n",
    "            ids,\n",
    "            question,\n",
    "            meta,\n",
    "            features,\n",
    "        ],\n",
    "        description=\"FAQ for MA\",\n",
    "    )\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f27f31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_npy(npy_file, batch_size=5000):\n",
    "    \"\"\"load the data from numpy\n",
    "    id: 1st column\n",
    "    meta: 2nd column\n",
    "    vector: 3rd to end columns (1536)\n",
    "    Returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    data = np.load(npy_file, allow_pickle=True)\n",
    "    \n",
    "    data_size = data.shape[1]\n",
    "    split_num = int(data_size/batch_size) + 1\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for data_batch in np.array_split(data, split_num, axis=1): \n",
    "        # data = data[:, :10500]\n",
    "        print(data_batch.shape)\n",
    "\n",
    "        # Get the 1st column values into a variable\n",
    "        question = data_batch[0]\n",
    "\n",
    "        ids = [generate_unique_id(q) for q in question]\n",
    "\n",
    "        # Get the 2nd column values into another variable\n",
    "        meta = data_batch[1]\n",
    "        # __import__(\"ipdb\").set_trace()\n",
    "\n",
    "        # Get all other columns (from the 3rd one onwards) into another variable\n",
    "        vec = data_batch[2]\n",
    "        \n",
    "        # res.append([ids, question, meta, vec])\n",
    "        res.append([ids,question, meta, vec])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "479a50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_npy_to_db(npy_file: Path, is_drop_collection=True):\n",
    "    # create collection if not exist\n",
    "\n",
    "    if is_drop_collection:\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "    if not utility.has_collection(COLLECTION_NAME):\n",
    "        schema = create_schema()\n",
    "        collection = Collection(\n",
    "            name=COLLECTION_NAME,\n",
    "            schema=schema,\n",
    "            using=\"default\",\n",
    "            shards_num=4,\n",
    "            consistency_level=\"Strong\",\n",
    "        )\n",
    "    # check collection number\n",
    "    collection = Collection(COLLECTION_NAME)\n",
    "    print(\n",
    "        \"Before Insert data, there is {0} records in collection {1}\".format(\n",
    "            collection.num_entities, COLLECTION_NAME\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # load data\n",
    "    data = load_data_from_npy(npy_file)\n",
    "    for i, data_batch in enumerate(data):\n",
    "        \n",
    "        mr = collection.insert(data_batch)\n",
    "        print(mr)\n",
    "        print(\n",
    "            \"After Insert data batch {0} , there is {1} records in collection {2}\".format(\n",
    "                i, collection.num_entities, COLLECTION_NAME\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # create index\n",
    "        index_params = {\n",
    "            \"metric_type\": \"L2\",\n",
    "            # \"metric_type\": \"IP\",\n",
    "            # \"index_type\": \"IVF_FLAT\",\n",
    "            \"index_type\": \"FLAT\",\n",
    "            \"params\": {\"nlist\": 1024},\n",
    "        }\n",
    "        collection.create_index(field_name=\"features\", index_params=index_params)\n",
    "\n",
    "        print(\"Index Created\")\n",
    "        collection.flush()\n",
    "        print(\"collection flushed\")\n",
    "        \n",
    "    print(\" Total: there is {0} records in collection {1}\".format(collection.num_entities, COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be074fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Insert data, there is 0 records in collection MA_FAQ_CACHE\n",
      "(3, 4497)\n",
      "(3, 4496)\n",
      "(3, 4496)\n",
      "(3, 4496)\n",
      "(insert count: 4497, delete count: 0, upsert count: 0, timestamp: 444114540015648771, success count: 4497, err count: 0)\n",
      "After Insert data batch 0 , there is 0 records in collection MA_FAQ_CACHE\n",
      "Index Created\n",
      "collection flushed\n",
      "(insert count: 4496, delete count: 0, upsert count: 0, timestamp: 444114541392166913, success count: 4496, err count: 0)\n",
      "After Insert data batch 1 , there is 4497 records in collection MA_FAQ_CACHE\n",
      "Index Created\n",
      "collection flushed\n",
      "(insert count: 4496, delete count: 0, upsert count: 0, timestamp: 444114542912339969, success count: 4496, err count: 0)\n",
      "After Insert data batch 2 , there is 8993 records in collection MA_FAQ_CACHE\n",
      "Index Created\n",
      "collection flushed\n",
      "(insert count: 4496, delete count: 0, upsert count: 0, timestamp: 444114544301703169, success count: 4496, err count: 0)\n",
      "After Insert data batch 3 , there is 13489 records in collection MA_FAQ_CACHE\n",
      "Index Created\n",
      "collection flushed\n",
      " Total: there is 17985 records in collection MA_FAQ_CACHE\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "load_data_from_npy_to_db(FAQ_ALL_DATA, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e6b70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 17985 records in collection MA_FAQ_CACHE\n",
      "[<pymilvus.orm.index.Index object at 0x7fe748207fd0>]\n"
     ]
    }
   ],
   "source": [
    "collection = Collection(COLLECTION_NAME)\n",
    "collection.load()\n",
    "print(\n",
    "    \"There is {0} records in collection {1}\".format(\n",
    "        collection.num_entities, COLLECTION_NAME\n",
    "    )\n",
    ")\n",
    "print(collection.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3eb86fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  auto_id: False\n",
      "  description: FAQ for MA\n",
      "  fields: [{\n",
      "    name: id\n",
      "    description: \n",
      "    type: 5\n",
      "    is_primary: True\n",
      "    auto_id: False\n",
      "  }, {\n",
      "    name: question\n",
      "    description: \n",
      "    type: 21\n",
      "    params: {'max_length': 200}\n",
      "  }, {\n",
      "    name: meta\n",
      "    description: \n",
      "    type: 21\n",
      "    params: {'max_length': 2000}\n",
      "  }, {\n",
      "    name: features\n",
      "    description: \n",
      "    type: 101\n",
      "    params: {'dim': 1536}\n",
      "  }]\n",
      "}\n",
      "FAQ for MA\n"
     ]
    }
   ],
   "source": [
    "print(collection.schema)                # Return the schema.CollectionSchema of the collection.\n",
    "print(collection.description)           # Return the description of the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c70038f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA_FAQ_CACHE\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(collection.name     )             # Return the name of the collection.\n",
    "print(collection.is_empty )             # Return the boolean value that indicates if the collection is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3e66d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17985\n",
      "{\n",
      "    name: id\n",
      "    description: \n",
      "    type: 5\n",
      "    is_primary: True\n",
      "    auto_id: False\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "print(collection.num_entities )         # Return the number of entities in the collection.\n",
    "print(collection.primary_field )        # Return the schema.FieldSchema of the primary key field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a393809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"name\": \"_default\", \"collection_name\": \"MA_FAQ_CACHE\", \"description\": \"\"}]\n",
      "[<pymilvus.orm.index.Index object at 0x7fc397506c50>]\n"
     ]
    }
   ],
   "source": [
    "print(collection.partitions)            # Return the list[Partition] object.\n",
    "print(collection.indexes )              # Return the list[Index] object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4574ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2ccc6",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aab5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54e8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"MA_FAQ_CACHE\"\n",
    "MILVUS_HOST = \"3.68.74.215\"\n",
    "MILVUS_PORT = \"19530\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ce3de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcf2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "endpoint_url = 'https://sandbox-openai-east-us.openai.azure.com/'\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = endpoint_url\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"911fe1b382ae49c08e99b98428ab8cee\"\n",
    "# The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "ENGINE_NAME_GPT_35 = \"gpt-35-turbo-version-0301\"\n",
    "ENGINE_NAME_GPT_4 = \"gpt-4\"\n",
    "ENGINE_NAME_GPT_4_32k = \"gpt-4-32k\"\n",
    "os.environ['OPENAI_API_KEY'] = \"911fe1b382ae49c08e99b98428ab8cee\"\n",
    "\n",
    "EMBEDDINGS = OpenAIEmbeddings(\n",
    "                    openai_api_base= endpoint_url,\n",
    "                    openai_api_type='azure',\n",
    "                    deployment='text-embedding-ada-002',\n",
    "                    openai_api_key=openai.api_key,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72af3f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3840aff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m Milvus(\n\u001b[1;32m      2\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39mEMBEDDINGS,\n\u001b[1;32m      3\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAQ_feat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# collection_name = \"FAQ_feat\",\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     connection_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m: MILVUS_HOST, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m: MILVUS_PORT},\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# primary_field = 'id',\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/tanpytor/lib/python3.11/site-packages/langchain/vectorstores/milvus.py:165\u001b[0m, in \u001b[0;36mMilvus.__init__\u001b[0;34m(self, embedding_function, collection_name, connection_args, consistency_level, index_params, search_params, drop_old)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Initialize the vector store\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init()\n",
      "File \u001b[0;32m/opt/conda/envs/tanpytor/lib/python3.11/site-packages/langchain/vectorstores/milvus.py:228\u001b[0m, in \u001b[0;36mMilvus._init\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_collection(embeddings, metadatas)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_fields()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_index()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_search_params()\n",
      "File \u001b[0;32m/opt/conda/envs/tanpytor/lib/python3.11/site-packages/langchain/vectorstores/milvus.py:308\u001b[0m, in \u001b[0;36mMilvus._extract_fields\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Since primary field is auto-id, no need to track it\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary_field)\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "vector_store = Milvus(\n",
    "    embedding_function=EMBEDDINGS,\n",
    "    collection_name=\"FAQ_feat\",\n",
    "    # collection_name = \"FAQ_feat\",\n",
    "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT},\n",
    "    # primary_field = 'id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665b2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0908 07:32:55.536906551    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n",
      "E0908 07:35:00.353561355    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n",
      "E0908 07:36:47.643699389    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n",
      "E0908 07:38:51.531033634    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n",
      "E0908 07:40:52.236142500    2699 ssl_transport_security.cc:1420]       Handshake failed with fatal error SSL_ERROR_SSL: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER.\n"
     ]
    }
   ],
   "source": [
    "def _response_format(resp):\n",
    "    \"\"\"\n",
    "    resp is the single response (doc,similarity)\n",
    "    \"\"\"\n",
    "    F_OUTPUT_FORMAT = \"\"\"\n",
    "        问题:{q}\n",
    "        答案:{a}\n",
    "        相似度:{s:.2f}\n",
    "    \"\"\".format\n",
    "    return F_OUTPUT_FORMAT(\n",
    "        q=resp[0].page_content.strip(),\n",
    "        a=resp[0].metadata[\"meta\"].strip(),\n",
    "        s=resp[1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ed0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responses_format(resp):\n",
    "    return \"\".join([_response_format(r) for r in resp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47282166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_response_with_threshold(\n",
    "    responses, threshold: float = V_SIMILARITY_THRESHOLD\n",
    "):\n",
    "    \"\"\"based on the threhold filter out the unsimilary document\n",
    "\n",
    "    Args:\n",
    "            responses (TODO): [(document,similary),(document,similary)]\n",
    "            threshold (float): similarity_threshold\n",
    "\n",
    "    Returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    similarity_idx = 1\n",
    "    return [r for r in responses if r[similarity_idx] <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4777249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_with_input(n=1):\n",
    "    \"\"\"for demo purpose\"\"\"\n",
    "    for line in fileinput.input():\n",
    "        res = \"\"\n",
    "        docs = vector_store.similarity_search_with_score(line.rstrip(), k=n)\n",
    "        docs = filter_response_with_threshold(docs)\n",
    "        if len(docs) == 0:\n",
    "            print(NOT_FOUND_MESSAGE)\n",
    "        print(responses_format(docs))\n",
    "\n",
    "\n",
    "def query(query_text: str, n=3) -> str:\n",
    "    \"\"\"find the most similar response in db, based on query_text\"\"\"\n",
    "    docs = vector_store.similarity_search_with_score(query_text.rstrip(), k=n) #tqy: Python rstrip() 删除 string 字符串末尾的指定字符，默认为空白符，包括空格、换行符、回车符、制表符\n",
    "    docs = filter_response_with_threshold(docs)\n",
    "    if len(docs) == 0:\n",
    "        return NOT_FOUND_MESSAGE\n",
    "    return responses_format(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    query_text = \"采集计划怎么做?\"\n",
    "    query_text2 = \"完成DDI商业对接后，默认会提取多少个月的数据？ \"\n",
    "    print(query(query_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4328efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # demo_with_input()\n",
    "    test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad2ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd819e53",
   "metadata": {},
   "source": [
    "## Milvus search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19ebc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "endpoint_url = 'https://sandbox-openai-east-us.openai.azure.com/'\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = endpoint_url\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"911fe1b382ae49c08e99b98428ab8cee\"\n",
    "# The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "ENGINE_NAME_GPT_35 = \"gpt-35-turbo-version-0301\"\n",
    "ENGINE_NAME_GPT_4 = \"gpt-4\"\n",
    "ENGINE_NAME_GPT_4_32k = \"gpt-4-32k\"\n",
    "os.environ['OPENAI_API_KEY'] = \"911fe1b382ae49c08e99b98428ab8cee\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "                    openai_api_base= endpoint_url,\n",
    "                    openai_api_type='azure',\n",
    "                    deployment='text-embedding-ada-002',\n",
    "                    openai_api_key=openai.api_key,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "253b3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection(\"MA_FAQ_CACHE\")\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "795d6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6bd78589",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"退货处理原则\"]\n",
    "search = embeddings.embed_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5d9a7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bab29ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.search(\n",
    "    data=search , \n",
    "    anns_field=\"features\", \n",
    "    # the sum of `offset` in `param` and `limit` \n",
    "    # should be less than 16384.\n",
    "    param=search_params,\n",
    "    limit=3,\n",
    "    # expr=\"random > -12\",\n",
    "    output_fields=[\"meta\"]\n",
    "    # expr=None,\n",
    "    # set the names of the fields you want to \n",
    "    # retrieve from the search result.\n",
    "    # output_fields=['title'],\n",
    "    # consistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ef84286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymilvus.orm.search.SearchResult at 0x7fe723b67510>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00035990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b721ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5123574733734131, 0.5171717405319214, 0.5207128524780273]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d365b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: 3488033127907708768, distance: 0.0, entity: {'meta': '{\"output_category\": \"FAQ\", \"text_response\": {\"standard_question\": \"退货处理原则\", \"response\": \"（1）不接受无正当理由或责任不应由拜耳承担的退换货要求\\\\n（2）只接受由一级经销商退回并且能够在SAP系统中查询到对应销售记录批次的产品。退回的药品必须与销售记录内容相符，批号一致，数量小于等于该批号销售数量\"}}'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit = results[0][0]\n",
    "hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd991332",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in res[0]:\n",
    "    meta = {x: result.entity.get(x) for x in output_fields}\n",
    "    doc = Document(page_content=meta.pop(self._text_field), metadata=meta)\n",
    "    pair = (doc, result.score)\n",
    "    ret.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5de1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6de04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e9f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe7362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volumes',\n",
       " '.ipynb_checkpoints',\n",
       " 'question_embeddings_all.npy',\n",
       " 'README.md',\n",
       " 'FAQ_embeddings_20230906.npy',\n",
       " 'FAQ_embeddings.npy',\n",
       " '.git',\n",
       " 'docker-compose.yml']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir(\"../../myfile/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09defc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question_embedding = \"../../myfile/question_embeddings_all.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(all_question_embedding, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c480dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义块大小\n",
    "block_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f52d4b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array can't be memory-mapped: Python objects in dtype.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 获取数组形状\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(all_question_embedding, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/tanpytor/lib/python3.11/site-packages/numpy/lib/npyio.py:453\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_pickle:\n\u001b[1;32m    452\u001b[0m         max_header_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                               max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(fid, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    457\u001b[0m                              pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs,\n\u001b[1;32m    458\u001b[0m                              max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n",
      "File \u001b[0;32m/opt/conda/envs/tanpytor/lib/python3.11/site-packages/numpy/lib/format.py:932\u001b[0m, in \u001b[0;36mopen_memmap\u001b[0;34m(filename, mode, dtype, shape, fortran_order, version, max_header_size)\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    931\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be memory-mapped: Python objects in dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 932\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    933\u001b[0m         offset \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "\u001b[0;31mValueError\u001b[0m: Array can't be memory-mapped: Python objects in dtype."
     ]
    }
   ],
   "source": [
    "# 获取数组形状\n",
    "shape = np.load(all_question_embedding, allow_pickle=True, mmap_mode='r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa9e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义读取的行数和起始位置\n",
    "rows = 10\n",
    "start = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐行读取\n",
    "with open(all_question_embedding, 'rb') as f:\n",
    "    # 跳过头部\n",
    "    f.seek(128 + start * np.dtype('float32').itemsize * np.load(all_question_embedding, allow_pickle=True).shape[1])\n",
    "    # 逐行读取\n",
    "    for i in range(rows):\n",
    "        data = np.fromfile(f, dtype=np.float32, count=np.load(all_question_embedding, allow_pickle=True).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd847c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数组\n",
    "slices = [slice(i, main(i + block_size, dim)) for i, dim in zip(range(0, shape[0], block_size), shape)]\n",
    "\n",
    "# 逐个块读取\n",
    "for sl in slices:\n",
    "    data = np.load('large_array.npy', mmap_mode='r', allow_pickle=True, encoding=None, order='K', shape=tuple([sl]) + shape[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tanpytor] *",
   "language": "python",
   "name": "conda-env-tanpytor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
